import argparse
import re
import tempfile

import duckdb
import pendulum
import requests
import telebot
from bs4 import BeautifulSoup
from telegramify_markdown import markdownify

GET_UP_MESSAGE_TEMPLATE = """ä»Šå¤©æ˜¯ {date}ï¼Œä»Šå¹´çš„ç¬¬ {day_of_year} å¤©ã€‚{weather_info}

{year_progress}

{today_index}

{coding_info}

{running_info}

ğŸ’¬ æ¯æ—¥åè¨€ï¼š
{quote}

ğŸ“œ æ¯æ—¥è¯—è¯ï¼š
{sentence}

{github_trending}

{oschina_news}
"""

TIMEZONE = "Asia/Shanghai"
SENTENCE_API = "https://v2.jinrishici.com/one.json"
QUOTE_API = "https://api.shadiao.pro/du"
OSCHINA_NEWS_URL = "https://www.oschina.net/news"
GITHUB_TRENDING_BASE_URL = "https://github.com/trending"
COINGECKO_PRICE_URL = "https://api.coingecko.com/api/v3/simple/price"
# å›½å†…é»„é‡‘ä»·æ ¼ï¼šä¸œæ–¹è´¢å¯Œ AU9999ï¼ˆä¸Šæµ·é‡‘äº¤æ‰€ï¼‰ï¼Œå•ä½ å…ƒ/å…‹
EASTMONEY_GOLD_URL = "https://push2.eastmoney.com/api/qt/stock/get"
EASTMONEY_GOLD_SECID = "118.AU9999"

DEFAULT_SENTENCE = """ã€Šè‹¦ç¬‹ã€‹
èµèŠ±å½’å»é©¬å¦‚é£ï¼Œ
å»é©¬å¦‚é£é…’åŠ›å¾®ï¼Œ
é…’åŠ›å¾®é†’æ—¶å·²æš®ï¼Œ
é†’æ—¶å·²æš®èµèŠ±å½’ã€‚

â€”â€” å®‹Â·è‹è½¼"""

DEFAULT_QUOTE = "ç”Ÿæ´»ä¸æ˜¯ç­‰å¾…æš´é£é›¨è¿‡å»ï¼Œè€Œæ˜¯è¦å­¦ä¼šåœ¨é›¨ä¸­è·³èˆã€‚"

# HTTP è¯·æ±‚å¤´å¸¸é‡
DEFAULT_HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
    "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8"
}

def _get_yesterday_time():
    """è·å–æ˜¨å¤©çš„æ—¶é—´å¯¹è±¡"""
    return pendulum.now(TIMEZONE).subtract(days=1)


def _safe_request(url, headers=None, params=None, timeout=10, method="get"):
    """å®‰å…¨çš„ HTTP è¯·æ±‚åŒ…è£…å‡½æ•°"""
    try:
        headers = headers or DEFAULT_HEADERS
        if method.lower() == "get":
            response = requests.get(url, headers=headers, params=params, timeout=timeout)
        else:
            response = requests.post(url, headers=headers, json=params, timeout=timeout)
        response.raise_for_status()
        return response, None
    except requests.exceptions.RequestException as e:
        return None, str(e)


def get_weather_info(city=None, api_key=None):
    """è·å–å¤©æ°”ä¿¡æ¯ï¼ˆä½¿ç”¨é«˜å¾·åœ°å›¾æ¥å£ï¼‰
    
    Args:
        city: åŸå¸‚åç§°ï¼ˆä¸­æ–‡ï¼‰ï¼Œå¦‚æœä¸º Noneï¼Œåˆ™é»˜è®¤æ­¦æ±‰
        api_key: é«˜å¾·åœ°å›¾ API Keyï¼Œå¿…éœ€å‚æ•°
    
    Returns:
        str: æ ¼å¼åŒ–åçš„å¤©æ°”ä¿¡æ¯
    """
    if city is None:
        city = "æ­¦æ±‰"
    
    try:
        if not api_key:
            print("æœªè®¾ç½®é«˜å¾·åœ°å›¾ API Keyï¼Œæ— æ³•ä½¿ç”¨é«˜å¾·åœ°å›¾ API")
            return ""
        
        url = "https://restapi.amap.com/v3/weather/weatherInfo"
        params = {
            "key": api_key,
            "city": city,
            "extensions": "all"
        }
        
        response, error = _safe_request(url, params=params, timeout=10)
        if error or not response:
            return ""
        
        data = response.json()
        
        if data.get("status") == "1" and data.get("info") == "OK":
            lives = data.get("lives", [])
            forecasts = data.get("forecasts", [])
            
            if forecasts and forecasts[0].get("casts"):
                casts = forecasts[0]["casts"]
                if casts:
                    today = casts[0]
                    weather_desc = today.get("dayweather", "æœªçŸ¥")
                    max_temp = today.get("daytemp", "N/A")
                    min_temp = today.get("nighttemp", "N/A")
                    return f"{city}å¤©æ°”:  {weather_desc} {min_temp}Â°C ~ {max_temp}Â°C"
            
            if lives:
                live = lives[0]
                weather_desc = live.get("weather", "æœªçŸ¥")
                temp = live.get("temperature", "N/A")
                return f"{city}å¤©æ°”:  {weather_desc} {temp}Â°C"
        
        return ""
    except Exception as e:
        print(f"é«˜å¾·åœ°å›¾ API è°ƒç”¨å¤±è´¥: {e}")
        return ""


def get_one_sentence():
    """è·å–ä»Šå¤©çš„ä¸€é¦–è¯—

    ä½¿ç”¨ä»Šæ—¥è¯—è¯ v2 API è·å–å®Œæ•´çš„è¯—è¯å†…å®¹
    è¿”å›æ ¼å¼ï¼šã€Šè¯—åã€‹\nè¯—è¯å†…å®¹\n\nâ€”â€” æœä»£Â·ä½œè€…
    """
    try:
        r = requests.get(SENTENCE_API, timeout=10)
        if r.ok:
            data = r.json()

            # è·å–è¯—è¯æ¥æºä¿¡æ¯
            origin = data.get("data", {}).get("origin", {})
            title = origin.get("title", "")
            dynasty = origin.get("dynasty", "")
            author = origin.get("author", "")
            content_list = origin.get("content", [])

            if content_list and title and author:
                # å°†è¯—è¯å†…å®¹æ•°ç»„åˆå¹¶ä¸ºå­—ç¬¦ä¸²ï¼ˆæ¯å¥ä¸€è¡Œï¼‰
                content = "\n".join(content_list)
                # æ ¼å¼åŒ–è¾“å‡ºï¼šã€Šè¯—åã€‹\nå†…å®¹\n\nâ€”â€” æœä»£Â·ä½œè€…
                poem = f"ã€Š{title}ã€‹\n{content}\n\nâ€”â€” {dynasty}Â·{author}"
                return poem

        return DEFAULT_SENTENCE
    except Exception as e:
        print(f"get SENTENCE_API wrong: {e}")
        return DEFAULT_SENTENCE


def get_daily_quote():
    """è·å–æ¯æ—¥åè¨€ï¼ˆé€šè¿‡APIæ¥å£ï¼‰
    
    Returns:
        str: æ¯æ—¥åè¨€
    """
    try:
        response, error = _safe_request(QUOTE_API, timeout=10)
        if error or not response:
            return DEFAULT_QUOTE
        
        data = response.json()
        quote_text = data.get("data", {}).get("text", "")
        
        if quote_text:
            return quote_text
        
        return DEFAULT_QUOTE
    except Exception as e:
        print(f"è·å–æ¯æ—¥åè¨€å¤±è´¥: {e}")
        return DEFAULT_QUOTE

def _get_repo_name_from_url(url):
    """ä»ä»“åº“ URL ä¸­æå–ä»“åº“åç§°"""
    return "/".join(url.split("/")[-2:])

def _process_search_items(items, username, item_type):
    """å¤„ç†æœç´¢ç»“æœï¼ˆPR æˆ– Issueï¼‰"""
    activities = []
    action_text = "åˆ›å»ºäº† PR" if item_type == "pr" else "åˆ›å»ºäº† Issue"

    for item in items:
        if item["user"]["login"] == username:
            repo_name = _get_repo_name_from_url(item["repository_url"])
            title = item["title"]
            url = item["html_url"]
            activities.append(f"{action_text}: [{title}]({url}) ({repo_name})")

    return activities

def _process_events(events, yesterday_start, yesterday_end):
    """å¤„ç†ç”¨æˆ·äº‹ä»¶"""
    activities = []

    for event in events[:100]:
        event_created = pendulum.parse(event["created_at"])

        if event_created < yesterday_start:
            break

        if not (yesterday_start <= event_created <= yesterday_end):
            continue

        if not event.get("public", True):
            continue

        event_type = event["type"]
        repo_name = event["repo"]["name"]

        if event_type == "PullRequestEvent":
            action = event["payload"].get("action")
            if action == "merged":
                pr_data = event["payload"]["pull_request"]
                activities.append(
                    f"åˆå¹¶äº† PR: [{pr_data['title']}]({pr_data['html_url']}) ({repo_name})"
                )
        elif event_type == "IssuesEvent":
            action = event["payload"].get("action")
            if action == "closed":
                issue_data = event["payload"]["issue"]
                activities.append(
                    f"å…³é—­äº† Issue: [{issue_data['title']}]({issue_data['html_url']}) ({repo_name})"
                )
        elif event_type == "WatchEvent":
            action = event["payload"].get("action")
            if action == "started":
                repo_url = f"https://github.com/{repo_name}"
                activities.append(f"Star äº†é¡¹ç›®: [{repo_name}]({repo_url})")

    return activities

def get_yesterday_github_activity(github_token=None, username=None):
    """è·å–æ˜¨å¤©çš„ GitHub æ´»åŠ¨"""
    if not username:
        return ""
    try:
        # æ—¶é—´è®¾ç½®
        yesterday = _get_yesterday_time()
        yesterday_start = yesterday.start_of("day").in_timezone("UTC")
        yesterday_end = yesterday.end_of("day").in_timezone("UTC")
        yesterday_date = yesterday.format("YYYY-MM-DD")

        # è¯·æ±‚å¤´è®¾ç½®
        headers = {}
        if github_token:
            headers.update(
                {
                    "Authorization": f"token {github_token}",
                    "Accept": "application/vnd.github.v3+json",
                }
            )

        activities = []

        # è·å–åˆ›å»ºçš„ PR
        search_url = "https://api.github.com/search/issues"
        response, error = _safe_request(
            search_url,
            headers=headers,
            params={
                "q": f"is:pr is:public involves:{username} created:{yesterday_date}",
                "per_page": 100,
            },
        )
        if response:
            pr_data = response.json()
            activities.extend(
                _process_search_items(pr_data.get("items", []), username, "pr")
            )
        elif error:
            print(f"æœç´¢ PR æ—¶å‡ºé”™: {error}")

        # è·å–åˆ›å»ºçš„ Issue
        response, error = _safe_request(
            search_url,
            headers=headers,
            params={
                "q": f"is:issue is:public involves:{username} created:{yesterday_date}",
                "per_page": 100,
            },
        )
        if response:
            issue_data = response.json()
            activities.extend(
                _process_search_items(issue_data.get("items", []), username, "issue")
            )
        elif error:
            print(f"æœç´¢ Issue æ—¶å‡ºé”™: {error}")

        # è·å–å…¶ä»–äº‹ä»¶ï¼ˆåˆå¹¶ã€å…³é—­ã€Star ç­‰ï¼‰
        events_url = f"https://api.github.com/users/{username}/events"
        all_activities = []

        for page in range(1, 4):  # æ£€æŸ¥å‰3é¡µï¼Œæ€»å…±çº¦90ä¸ªäº‹ä»¶
            response, error = _safe_request(
                events_url, headers=headers, params={"page": page, "per_page": 30}
            )

            if error:
                print(f"è·å–ç¬¬ {page} é¡µ Events æ—¶å‡ºé”™: {error}")
                continue

            if not response:
                break  # æ²¡æœ‰æ›´å¤šäº‹ä»¶äº†

            events_data = response.json()
            page_activities = _process_events(
                events_data, yesterday_start, yesterday_end
            )
            all_activities.extend(page_activities)

            # å¦‚æœè¿™ä¸€é¡µäº‹ä»¶æ•°å°‘äº30ï¼Œè¯´æ˜å·²ç»åˆ°åº•äº†
            if len(events_data) < 30:
                break

        activities.extend(all_activities)

        # è¿”å›ç»“æœ
        if activities:
            # å»é‡å¹¶é™åˆ¶æ•°é‡
            unique_activities = list(dict.fromkeys(activities))
            return "ğŸ™ GitHubï¼š\n" + "\n".join(
                f"â€¢ {activity}" for activity in unique_activities[:8]
            )

        return ""

    except Exception as e:
        print(f"Error getting GitHub activity: {e}")
        return ""

def get_yesterday_coding_time(wakatime_token=None):
    """è·å–æ˜¨å¤©çš„ç¼–ç¨‹æ—¶é—´"""
    if not wakatime_token:
        return ""
    
    try:
        yesterday = _get_yesterday_time()
        yesterday_date = yesterday.format("YYYY-MM-DD")

        url = f'https://wakatime.com/api/v1/users/current/summaries?api_key={wakatime_token}&start={yesterday_date}&end={yesterday_date}'

        response, error = _safe_request(url)
        if error:
            print(f"è·å– WakaTime æ•°æ®å¤±è´¥: {error}")
            return ""

        if response.status_code == 200:
            result = response.json()
            cumulative_total = result.get('cumulative_total', {})
            cost = round(cumulative_total.get('seconds', 0))
            
            if cost > 0:
                # æ ¼å¼åŒ–æ—¶é—´æ–‡æœ¬
                cost_text = cumulative_total.get('text', '')
                cost_text = cost_text.replace("hrs", "å°æ—¶").replace("hr", "å°æ—¶")
                cost_text = cost_text.replace("mins", "åˆ†é’Ÿ").replace("min", "åˆ†é’Ÿ")
                cost_text = cost_text.replace("secs", "ç§’").replace("sec", "ç§’")
                
                lines = [f"âŒ¨ï¸ ç¼–ç¨‹æ—¶é—´ï¼š\nâ€¢ æ˜¨å¤©å†™ä»£ç èŠ±äº† {cost_text}"]
                
                # è·å–ç»Ÿè®¡ä¿¡æ¯
                data = result.get('data', [])
                if data and len(data) > 0:
                    day_data = data[0]
                    
                    # è·å–ç¼–è¾‘å™¨ç»Ÿè®¡ä¿¡æ¯
                    editors = day_data.get('editors', [])
                    if editors:
                        # æ˜¾ç¤ºå‰3ä¸ªç¼–è¾‘å™¨
                        top_editors = editors[:3]
                        editor_texts = []
                        for editor in top_editors:
                            editor_name = editor.get('name', '')
                            editor_percent = editor.get('percent', 0)
                            if editor_name and editor_percent > 0:
                                editor_texts.append(f"{editor_name} {editor_percent:.0f}%")
                        
                        if editor_texts:
                            lines.append(f"â€¢ ä½¿ç”¨ç¼–è¾‘å™¨ï¼š{', '.join(editor_texts)}")
                    
                    # è·å–è¯­è¨€ç»Ÿè®¡ä¿¡æ¯
                    languages = day_data.get('languages', [])
                    if languages:
                        # æ˜¾ç¤ºå‰3ä¸ªè¯­è¨€
                        top_languages = languages[:3]
                        lang_texts = []
                        for lang in top_languages:
                            lang_name = lang.get('name', '')
                            lang_percent = lang.get('percent', 0)
                            if lang_name and lang_percent > 0:
                                lang_texts.append(f"{lang_name} {lang_percent:.0f}%")
                        
                        if lang_texts:
                            lines.append(f"â€¢ ä¸»è¦è¯­è¨€ï¼š{', '.join(lang_texts)}")
                
                return "\n".join(lines)
            else:
                return "âŒ¨ï¸ ç¼–ç¨‹æ—¶é—´ï¼š\nâ€¢ æ˜¨å¤©æ²¡å†™ä»£ç "
        else:
            print(f"è·å– WakaTime æ•°æ®å¤±è´¥: {response.status_code}")
            return ""
    except Exception as e:
        print(f"Error getting coding time: {e}")
        return ""

def get_running_distance(username=None):
    """è·å–è·‘æ­¥è·ç¦»ç»Ÿè®¡"""
    if not username:
        return ""
    
    try:
        url = f"https://github.com/{username}/running_page/raw/refs/heads/master/run_page/data.parquet"
        response, error = _safe_request(url)
        if error or not response.ok:
            return ""

        with tempfile.NamedTemporaryFile() as temp_file:
            temp_file.write(response.content)
            temp_file.flush()

            with duckdb.connect() as conn:
                now = pendulum.now(TIMEZONE)
                yesterday = _get_yesterday_time()
                month_start = now.start_of("month")
                year_start = now.start_of("year")
                tomorrow = now.add(days=1)

                # æ„å»ºæŸ¥è¯¢çš„é€šç”¨éƒ¨åˆ†
                base_query = """
                SELECT
                    COUNT(*) as count,
                    ROUND(SUM(distance)/1000, 2) as total_km
                FROM read_parquet('{file}')
                WHERE {condition}
                """

                queries = {
                    "yesterday": base_query.format(
                        file=temp_file.name,
                        condition=f"DATE(start_date_local) = '{yesterday.to_date_string()}'"
                    ),
                    "month": base_query.format(
                        file=temp_file.name,
                        condition=f"start_date_local >= '{month_start.to_date_string()}' AND start_date_local < '{tomorrow.to_date_string()}'"
                    ),
                    "year": base_query.format(
                        file=temp_file.name,
                        condition=f"start_date_local >= '{year_start.to_date_string()}' AND start_date_local < '{tomorrow.to_date_string()}'"
                    )
                }

                results = {}
                for key, query in queries.items():
                    result = conn.execute(query).fetchone()
                    results[key] = result

            # æ ¼å¼åŒ–è¾“å‡º
            running_info_parts = []
            period_info = [
                ("yesterday", "æ˜¨å¤©", results["yesterday"]),
                ("month", "æœ¬æœˆ", results["month"]),
                ("year", "ä»Šå¹´", results["year"]),
            ]

            for key, label, result in period_info:
                if result and result[0] > 0:
                    running_info_parts.append(f"â€¢ {label}è·‘äº† {result[1]} å…¬é‡Œ")
                else:
                    running_info_parts.append(f"â€¢ {label}æ²¡è·‘")

            return "ğŸƒâ€â™€ï¸è·‘æ­¥è·ç¦»ï¼š\n" + "\n".join(running_info_parts)

    except Exception as e:
        print(f"Error getting running data: {e}")
        return ""


def get_today_index():
    """è·å–ä»Šæ—¥æŒ‡æ•°ï¼šé»„é‡‘ï¼ˆäººæ°‘å¸ å…ƒ/å…‹ï¼Œå›½å†…æ¥å£ï¼‰å’Œæ¯”ç‰¹å¸ï¼ˆç¾å…ƒï¼‰ä»·æ ¼ã€‚

    Returns:
        str: æ ¼å¼åŒ–åçš„ä»Šæ—¥æŒ‡æ•°ä¿¡æ¯
    """
    parts = []

    # é»„é‡‘ä»·æ ¼ï¼ˆä¸œæ–¹è´¢å¯Œ AU9999ï¼Œä¸Šæµ·é‡‘äº¤æ‰€ï¼Œäººæ°‘å¸ å…ƒ/å…‹ï¼‰
    try:
        response, error = _safe_request(
            EASTMONEY_GOLD_URL,
            params={
                "secid": EASTMONEY_GOLD_SECID,
                "fields": "f57,f58,f43",  # ä»£ç ,åç§°,æœ€æ–°ä»·(ç°ä»·)
            },
            timeout=10,
        )
        if not error and response and response.status_code == 200:
            data = response.json()
            inner = data.get("data") or {}
            # f43 ä¸ºæœ€æ–°ä»·(ç°ä»·)ï¼Œå•ä½ï¼šåˆ†/å…‹ï¼Œé™¤ä»¥ 100 å¾— å…ƒ/å…‹
            price_raw = inner.get("f43")
            if price_raw is not None:
                price_yuan_per_gram = float(price_raw) / 100
                parts.append(f"â€¢ é»„é‡‘ï¼š{price_yuan_per_gram:,.2f} å…ƒ/å…‹")
    except Exception as e:
        print(f"è·å–é»„é‡‘ä»·æ ¼å¤±è´¥: {e}")

    # æ¯”ç‰¹å¸ä»·æ ¼ï¼ˆCoinGeckoï¼Œå…è´¹æ— éœ€ keyï¼‰
    try:
        response, error = _safe_request(
            COINGECKO_PRICE_URL,
            params={"ids": "bitcoin", "vs_currencies": "usd"},
            timeout=10,
        )
        if not error and response and response.status_code == 200:
            data = response.json()
            btc = data.get("bitcoin", {}).get("usd")
            if btc is not None:
                if btc >= 1000:
                    parts.append(f"â€¢ æ¯”ç‰¹å¸ï¼š${btc:,.0f} USD")
                else:
                    parts.append(f"â€¢ æ¯”ç‰¹å¸ï¼š${btc:,.2f} USD")
    except Exception as e:
        print(f"è·å–æ¯”ç‰¹å¸ä»·æ ¼å¤±è´¥: {e}")

    if not parts:
        return ""

    return "ğŸ“ˆ ä»Šæ—¥æŒ‡æ•°ï¼š\n" + "\n".join(parts)


def get_day_of_year():
    now = pendulum.now(TIMEZONE)
    return now.day_of_year

def get_year_progress():
    """è·å–ä»Šå¹´çš„è¿›åº¦æ¡"""
    now = pendulum.now(TIMEZONE)
    day_of_year = now.day_of_year

    # åˆ¤æ–­æ˜¯å¦ä¸ºé—°å¹´
    is_leap_year = now.year % 4 == 0 and (now.year % 100 != 0 or now.year % 400 == 0)
    total_days = 366 if is_leap_year else 365

    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
    progress_percent = (day_of_year / total_days) * 100

    # ç”Ÿæˆè¿›åº¦æ¡
    progress_bar_width = 20
    filled_blocks = int((day_of_year / total_days) * progress_bar_width)
    empty_blocks = progress_bar_width - filled_blocks

    progress_bar = "â–ˆ" * filled_blocks + "â–‘" * empty_blocks

    return f"{progress_bar} {progress_percent:.1f}% ({day_of_year}/{total_days})"


def get_oschina_news(limit=5):
    """è·å–å¼€æºä¸­å›½æœ€æ–°èµ„è®¯
    
    Args:
        limit: è¿”å›çš„èµ„è®¯æ•°é‡ï¼Œé»˜è®¤5æ¡
    
    Returns:
        str: æ ¼å¼åŒ–åçš„èµ„è®¯æ–‡æœ¬
    """
    try:
        response, error = _safe_request(OSCHINA_NEWS_URL, timeout=10)
        if error:
            raise Exception(error)
        
        soup = BeautifulSoup(response.text, "html.parser")
        news_list = []
        seen_urls = set()
        
        # æŸ¥æ‰¾æ‰€æœ‰æ–°é—»æ¡ç›®å®¹å™¨ï¼ˆclassåŒ…å«itemå’Œnews-itemï¼‰
        news_items = soup.find_all("div", class_=re.compile(r"item.*news-item|news-item.*item"))
        
        for item in news_items:
            if len(news_list) >= limit:
                break
            
            # ä» data-url å±æ€§è·å–URL
            url = item.get("data-url", "")
            if not url:
                # å°è¯•ä»å†…éƒ¨é“¾æ¥è·å–
                link = item.find("a", href=re.compile(r"/news/\d+"))
                if link:
                    url = link.get("href", "")
            
            if not url:
                continue
            
            # å»æ‰é”šç‚¹
            url = url.split("#")[0]
            
            # æ„å»ºå®Œæ•´URL
            if url.startswith("/"):
                url = f"https://www.oschina.net{url}"
            elif not url.startswith("http"):
                continue
            
            # å»é‡
            if url in seen_urls:
                continue
            seen_urls.add(url)
            
            # æå–æ ‡é¢˜ï¼ˆä» h3.header .title æˆ– h3 ä¸­ï¼‰
            title_elem = item.find("h3", class_="header")
            if title_elem:
                title_div = title_elem.find("div", class_="title")
                if title_div:
                    title = title_div.get_text(strip=True)
                else:
                    title = title_elem.get_text(strip=True)
            else:
                title_elem = item.find("h3")
                title = title_elem.get_text(strip=True) if title_elem else ""
            
            if not title or len(title) < 5:
                continue
            
            news_list.append({
                "title": title,
                "url": url
            })
        
        if not news_list:
            return ""
        
        # æ ¼å¼åŒ–èµ„è®¯
        lines = ["ğŸ“° OSChina æœ€æ–°èµ„è®¯ï¼š"]
        for i, news in enumerate(news_list, 1):
            lines.append(f"â€¢ [{news['title']}]({news['url']})")
        
        return "\n".join(lines)
        
    except Exception as e:
        print(f"è·å– OSChina èµ„è®¯å¤±è´¥: {e}")
        return ""


def get_github_trending(language=None, limit=5):
    """è·å– GitHub Trending ä»“åº“
    
    Args:
        language: ç¼–ç¨‹è¯­è¨€ï¼Œå¦‚ 'python', 'javascript', 'java' ç­‰ï¼ŒNone è¡¨ç¤ºæ‰€æœ‰è¯­è¨€
        limit: è¿”å›çš„ä»“åº“æ•°é‡ï¼Œé»˜è®¤5ä¸ª
    
    Returns:
        str: æ ¼å¼åŒ–åçš„ Trending ä¿¡æ¯
    """
    try:
        # æ„å»º URL
        if language:
            url = f"{GITHUB_TRENDING_BASE_URL}/{language}?since=daily&spoken_language_code="
        else:
            url = f"{GITHUB_TRENDING_BASE_URL}?since=daily&spoken_language_code="
        
        response, error = _safe_request(url, timeout=15)
        if error:
            raise Exception(error)
        
        soup = BeautifulSoup(response.text, "html.parser")
        repos = []
        
        # GitHub Trending é¡µé¢çš„ç»“æ„ï¼šæ¯ä¸ªä»“åº“åœ¨ä¸€ä¸ª article æ ‡ç­¾ä¸­
        articles = soup.find_all("article", class_="Box-row")
        
        for article in articles[:limit]:
            # è·å–ä»“åº“åç§°å’Œé“¾æ¥
            h2 = article.find("h2", class_="h3")
            if not h2:
                continue
            
            link = h2.find("a")
            if not link:
                continue
            
            repo_name = link.get_text(strip=True)
            repo_url = link.get("href", "")
            if repo_url.startswith("/"):
                repo_url = f"https://github.com{repo_url}"
            
            repos.append({
                "name": repo_name,
                "url": repo_url
            })
        
        if not repos:
            return ""
        
        # æ ¼å¼åŒ–è¾“å‡º
        lines = ["â­ GitHub Trending For Javaï¼š"]
        for repo in repos:
            lines.append(f"â€¢ [{repo['name']}]({repo['url']})")
        
        return "\n".join(lines)
        
    except Exception as e:
        print(f"è·å– GitHub Trending å¤±è´¥: {e}")
        return ""


def make_get_up_message(github_token, username=None, wakatime_token=None, city=None, trending_language=None, amap_api_key=None):
    try:
        sentence = get_one_sentence()
    except Exception as e:
        print(str(e))
        sentence = DEFAULT_SENTENCE

    try:
        quote = get_daily_quote()
    except Exception as e:
        print(str(e))
        quote = DEFAULT_QUOTE

    now = pendulum.now(TIMEZONE)
    date = now.format("YYYYå¹´MMæœˆDDæ—¥")
    day_of_year = get_day_of_year()
    year_progress = get_year_progress()
    weather_info = get_weather_info(city, amap_api_key)
    coding_info = get_yesterday_coding_time(wakatime_token)
    github_activity = get_yesterday_github_activity(github_token, username)
    running_info = get_running_distance(username)
    github_trending = get_github_trending(language=trending_language, limit=5)
    oschina_news = get_oschina_news(limit=5)
    today_index = get_today_index()

    return (
        sentence,
        date,
        day_of_year,
        year_progress,
        weather_info,
        coding_info,
        github_activity,
        running_info,
        github_trending,
        oschina_news,
        quote,
        today_index,
    )


def main(
    github_token,
    username,
    tele_token,
    tele_chat_id,
    wakatime_token=None,
    city="æ­¦æ±‰",
    trending_language="java",
    amap_api_key=None,
):
    (
        sentence,
        date,
        day_of_year,
        year_progress,
        weather_info,
        coding_info,
        github_activity,
        running_info,
        github_trending,
        oschina_news,
        quote,
        today_index,
    ) = make_get_up_message(github_token, username, wakatime_token, city, trending_language, amap_api_key)

    body = GET_UP_MESSAGE_TEMPLATE.format(
        date=date,
        sentence=sentence,
        day_of_year=day_of_year,
        year_progress=year_progress,
        weather_info=weather_info,
        coding_info=coding_info,
        github_activity=github_activity,
        running_info=running_info,
        github_trending=github_trending,
        oschina_news=oschina_news,
        quote=quote,
        today_index=today_index,
    )

    print(body)

    if tele_token and tele_chat_id:
        bot = telebot.TeleBot(tele_token)
        try:
            formatted_body = markdownify(body)
            bot.send_message(
                tele_chat_id,
                formatted_body,
                parse_mode="MarkdownV2",
                disable_notification=True,
            )
        except Exception as e:
            print(str(e))

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("username", help="GitHub username")
    parser.add_argument("github_token", help="github_token")
    parser.add_argument(
        "--tele_token", help="tele_token", nargs="?", default="", const=""
    )
    parser.add_argument(
        "--tele_chat_id", help="tele_chat_id", nargs="?", default="", const=""
    )
    parser.add_argument(
        "--wakatime_token", help="wakatime_token", nargs="?", default="", const=""
    )
    parser.add_argument(
        "--city", help="åŸå¸‚åç§°ï¼ˆå¤©æ°”æŸ¥è¯¢ï¼Œé»˜è®¤ï¼šæ­¦æ±‰ï¼‰", nargs="?", default="", const=""
    )
    parser.add_argument(
        "--trending_language", help="GitHub Trending ç¼–ç¨‹è¯­è¨€ï¼ˆé»˜è®¤ï¼šjavaï¼‰", nargs="?", default="", const=""
    )
    parser.add_argument(
        "--amap_api_key", help="é«˜å¾·åœ°å›¾ API Keyï¼ˆå¤©æ°”æŸ¥è¯¢ï¼‰", nargs="?", default="", const=""
    )
    options = parser.parse_args()
    
    main_kwargs = {
        "github_token": options.github_token,
        "username": options.username,
        "tele_token": options.tele_token,
        "tele_chat_id": options.tele_chat_id,
    }
    
    if options.wakatime_token:
        main_kwargs["wakatime_token"] = options.wakatime_token
    
    if options.city:
        main_kwargs["city"] = options.city
    
    if options.trending_language:
        main_kwargs["trending_language"] = options.trending_language
    
    if options.amap_api_key:
        main_kwargs["amap_api_key"] = options.amap_api_key
    
    main(**main_kwargs)